import os
import sys
import json
import logging
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…Ø·ÙˆØ±
from dominator_brain import strategic_intelligence_core, WPIL_DOMINATOR_SYSTEM

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„Ø³Ø¬Ù„Ø§Øª
app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logger = logging.getLogger(__name__)

# ========= Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø±ÙƒØ§Øª AI (ØªØ­Ø¯ÙŠØ« 21 Ø¯ÙŠØ³Ù…Ø¨Ø± 2025) =========
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Ù…ØµÙÙˆÙØ© Ø§Ù„Ù‡ÙŠÙ…Ù†Ø© - ØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…ØªÙƒ "Ø§Ù„Ù…ØªØ§Ø­Ø©" ÙŠÙ‚ÙŠÙ†Ø§Ù‹
MODELS_PRIORITY = [
    "gemini-2.5-flash",       # Ø·Ø±Ø§Ø² Ø§Ù„Ù‚Ù…Ø© Ù„Ø¹Ø§Ù… 2025 (Ù…ØªØ§Ø­ ÙÙŠ Ù‚Ø§Ø¦Ù…ØªÙƒ)
    "gemini-2.0-flash",       # Ø§Ù„Ø·Ø±Ø§Ø² Ø§Ù„Ù…Ø³ØªÙ‚Ø± ÙØ§Ø¦Ù‚ Ø§Ù„Ø³Ø±Ø¹Ø© (Ù…ØªØ§Ø­ ÙÙŠ Ù‚Ø§Ø¦Ù…ØªÙƒ)
    "gemini-flash-latest"     # Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ´ØºÙŠÙ„ (Ù…ØªØ§Ø­ ÙÙŠ Ù‚Ø§Ø¦Ù…ØªÙƒ)
]

def get_ai_response_with_failover(prompt: str) -> str:
    last_error = ""
    for model_name in MODELS_PRIORITY:
        try:
            logger.info(f"Deploying Brain on: {model_name}")
            # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚ÙŠØ©
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            last_error = str(e)
            logger.error(f"Execution failed on {model_name}: {last_error}")
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ 404 Ø£Ùˆ 429ØŒ Ù†Ù†ØªÙ‚Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ ÙÙˆØ±Ø§Ù‹
            if "404" in last_error or "429" in last_error:
                continue
            return f"Strategic Engine Error: {last_error}"
    
    return f"âš ï¸ Ø§Ù†Ù‚Ø·Ø§Ø¹ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹. Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø£Ø®ÙŠØ±: {last_error}"

# ========= Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø°ÙƒÙŠØ§Ù‹ =========
def extract_ui_data():
    data = {}
    try:
        data = request.get_json(force=True, silent=True) or {}
    except: data = {}
    
    if request.form: data.update(request.form.to_dict())

    # Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù…Ø³Ù…ÙŠØ§Øª JavaScript ÙÙŠ index.html
    idea = data.get('text') or data.get('idea') or data.get('topic') or ""
    seed = data.get('winning_post') or data.get('seed') or ""
    style = data.get('style_dna') or data.get('style') or "Professional"
    
    return str(idea).strip(), str(seed).strip(), str(style).strip()

# ========= Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø© =========

@app.route("/", methods=["GET"])
def home():
    return render_template("index.html")

@app.route("/generate/<platform>", methods=["POST", "GET"])
@app.route("/remix", methods=["POST", "GET"])
def handle_execution(platform="linkedin"):
    if request.method == "GET":
        return jsonify({"status": "ready"}), 200

    if request.path == "/remix": platform = "linkedin"

    idea, seed, style = extract_ui_data()
    actual_content = idea if idea else seed
    
    if not actual_content:
        return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø§Ø¯Ø© Ø®Ø§Ù… Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù„ÙŠÙ‡Ø§"}), 400

    try:
        # 1. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ
        brain = strategic_intelligence_core(idea, platform, style, seed)
        
        # 2. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ÙŠØ«Ø§Ù‚ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¹Ø¨Ø± Ù†Ø¸Ø§Ù… Ø§Ù„Ù€ Failover
        final_prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØ§Ù„Ù…Ù†ØµØ© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©: {platform}\nØ§Ù„Ù…Ù‡Ù…Ø©: {brain['transformed_input']}\nØ§Ù„Ø£Ø³Ù„ÙˆØ¨: {style}"
        generated_text = get_ai_response_with_failover(final_prompt)

        payload = {
            "platform": platform,
            "text": generated_text,
            "trace": brain["logic_trace"],
            "remixed_seed": idea if idea else seed,
            "sic_transformed_input": brain['transformed_input']
        }

        # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„Ù…Ù†ØµØ© TikTok
        if platform == "tiktok" and "video_segments" in brain:
            formatted_prompts = "ğŸ¥ **SUPREME ADVISOR VIDEO BLUEPRINT (9:16)**\n\n"
            for seg in brain["video_segments"]:
                formatted_prompts += f"### Scene: {seg['time']}\n```text\n{seg['prompt']}\n```\n\n"
            payload["video_prompt"] = formatted_prompts
        else:
            payload["video_prompt"] = brain.get("visual_prompt", "")

        return jsonify(payload), 200

    except Exception as e:
        logger.error(f"SYSTEM CRITICAL CRASH: {str(e)}")
        return jsonify({"error": f"Internal Crash: {str(e)}"}), 500

if __name__ == "__main__":
    port = int(os.getenv("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
