import os
import re
import requests
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
from dominator_brain import strategic_intelligence_core, alchemy_fusion_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)

# ========= ØªØ±Ø³Ø§Ù†Ø© Nebula Ù„Ø¹Ø§Ù… 2025 (Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ØªØ§Ø­ Ù„Ø¯ÙŠÙƒ) =========
MODELS_POOL = [
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.0-flash-lite-001",
    "gemini-flash-latest",
    "gemini-pro-latest"
]

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
APIFY_KEY = os.getenv("APIFY_API_KEY")

def get_ai_response_nebula(prompt: str) -> str:
    """Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Nebula Ù„Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù‚Ø³Ø±ÙŠ"""
    for model_name in MODELS_POOL:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except: continue
    return "ğŸš¨ ÙƒØ§ÙØ© Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ù…Ø´ØºÙˆÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."

def fetch_live_dna(niche):
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· ØªØ­Ù‚Ù‚ Ø®Ø§Ø±Ø¬ÙŠØ©"""
    fallback_url = f"https://twitter.com/search?q={niche}&f=live"
    if APIFY_KEY:
        try:
            url = f"https://api.apify.com/v2/acts/apidojo~tweet-scraper/run-sync-get-dataset-items?token={APIFY_KEY}"
            res = requests.post(url, json={"searchTerms": [niche], "maxTweets": 5, "searchMode": "top"}, timeout=20)
            if res.status_code in [200, 201]:
                data = res.json()
                if data:
                    return [{
                        "text": i.get("text") or i.get("full_text") or "DNA Sample",
                        "engagement": f"{i.get('favorite_count', 0)}",
                        "author": i.get("user", {}).get("screen_name", "Elite_User"),
                        "url": i.get("url") or f"https://twitter.com/i/web/status/{i.get('id_str')}",
                        "score": 85 + (int(i.get('favorite_count', 0)) % 15)
                    } for i in data if (i.get("text") or i.get("full_text"))]
        except: pass
    return [{"text": f"ØªØ­Ù„ÙŠÙ„ Ø³ÙŠØ§Ø¯ÙŠ Ù„ØªØ±Ù†Ø¯Ø§Øª {niche}", "engagement": "150K", "author": "Dominator_AI", "url": fallback_url, "score": 95}]

def parse_output(text):
    parts = {"linkedin": "", "twitter": "", "tiktok": ""}
    for p in parts:
        match = re.search(rf"\[{p.upper()}\](.*?)(\[|$)", text, re.S | re.I)
        parts[p] = match.group(1).strip() if match else "ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚Ø³Ù…"
    return parts

@app.route("/")
def home(): return render_template("index.html")

@app.route("/alchemy/discover", methods=["POST"])
def discover():
    data = request.get_json(silent=True) or {}
    niche = data.get("niche", "Ø±ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ø¹Ù…Ø§Ù„")
    posts = fetch_live_dna(niche)
    fusion = alchemy_fusion_core(posts, niche)
    output = get_ai_response_nebula(f"{WPIL_DOMINATOR_SYSTEM}\n{fusion['synthesis_task']}")
    return jsonify({"super_post": output, "sources": posts}), 200

@app.route("/generate_all", methods=["POST"])
def generate():
    data = request.get_json(silent=True) or {}
    idea = data.get("text", "Ø§Ù„Ø³ÙŠØ§Ø¯Ø©")
    prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ù„Ù€ [LINKEDIN], [TWITTER], [TIKTOK] Ù„Ù„ÙÙƒØ±Ø©: {idea}"
    raw = get_ai_response_nebula(prompt)
    parsed = parse_output(raw)
    brain = strategic_intelligence_core(idea)
    return jsonify({**parsed, "video_prompt": brain["video_segments"]}), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
