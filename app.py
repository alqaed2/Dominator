import os
import sys
import json
import logging
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…Ø·ÙˆØ±
from dominator_brain import strategic_intelligence_core, WPIL_DOMINATOR_SYSTEM

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„Ø³Ø¬Ù„Ø§Øª
app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logger = logging.getLogger(__name__)

# ========= Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø±ÙƒØ§Øª AI 2025 =========
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Ù…ØµÙÙˆÙØ© Ø§Ù„Ù‡ÙŠÙ…Ù†Ø© Ù„ØªØ¬Ø§ÙˆØ² Ø®Ø·Ø£ 429 (Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø²Ø§Ø¦Ø¯)
MODELS_PRIORITY = [
    "gemini-2.0-flash",       # Ø§Ù„ØªÙˆØ§Ø²Ù† Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ
    "gemini-1.5-flash",       # Ø³Ø±Ø¹Ø© ÙØ§Ø¦Ù‚Ø© ÙˆØ­Ø¯ÙˆØ¯ Ø¹Ø§Ù„ÙŠØ©
    "gemini-flash-latest"     # Ø§Ù„Ù…Ù„Ø§Ø° Ø§Ù„Ø£Ø®ÙŠØ± Ù„Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
]

def get_ai_response_with_failover(prompt: str) -> str:
    last_error = ""
    for model_name in MODELS_PRIORITY:
        try:
            logger.info(f"Attempting execution with: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            last_error = str(e)
            if "429" in last_error:
                logger.warning(f"Model {model_name} rate limited. Switching...")
                continue
            return f"Critical Engine Error: {last_error}"
    return f"âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ù…Ø´ØºÙˆÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø©. Ø§Ù„Ø®Ø·Ø£: {last_error}"

# ========= Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù€ index.html =========
def extract_ui_data():
    data = {}
    try:
        data = request.get_json(force=True, silent=True) or {}
    except: data = {}
    
    if request.form: data.update(request.form.to_dict())

    # Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¹ Ù…Ø³Ù…ÙŠØ§Øª JavaScript ÙÙŠ index.html
    idea = data.get('text') or data.get('idea') or data.get('topic') or ""
    seed = data.get('winning_post') or data.get('seed') or ""
    style = data.get('style_dna') or data.get('style') or "Professional"
    
    return str(idea).strip(), str(seed).strip(), str(style).strip()

# ========= Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù‡ÙŠÙ…Ù†Ø© =========

@app.route("/", methods=["GET"])
def home():
    return render_template("index.html")

@app.route("/health")
def health():
    return jsonify({"status": "online", "system": "AI DOMINATOR V3.0"}), 200

@app.route("/generate/<platform>", methods=["POST", "GET"])
@app.route("/remix", methods=["POST", "GET"])
def handle_execution(platform="linkedin"):
    if request.method == "GET":
        return jsonify({"info": "POST expected"}), 200

    if request.path == "/remix": platform = "linkedin"

    # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    idea, seed, style = extract_ui_data()
    actual_content = idea if idea else seed
    
    if not actual_content:
        return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ ÙÙƒØ±Ø© Ø£Ùˆ Ù…Ù†Ø´ÙˆØ± Ù…Ø±Ø¬Ø¹ÙŠ Ù„Ù„Ø¨Ø¯Ø¡"}), 400

    try:
        # 2. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ù…Ø§Øº Ø¨Ù…Ù†Ø·Ù‚ Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©
        brain = strategic_intelligence_core(idea, platform, style, seed)
        
        # 3. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø£Ù…Ø± ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù†Øµ
        final_prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØ§Ù„Ù…Ù†ØµØ©: {platform}\nØ§Ù„Ù…Ù‡Ù…Ø©: {brain['transformed_input']}\nØ§Ù„Ø£Ø³Ù„ÙˆØ¨: {style}"
        generated_text = get_ai_response_with_failover(final_prompt)

        payload = {
            "platform": platform,
            "text": generated_text,
            "trace": brain["logic_trace"],
            "remixed_seed": idea if idea else seed,
            "sic_transformed_input": brain['transformed_input']
        }

        # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù‚Ø§Ø·Ø¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„ØªÙŠÙƒ ØªÙˆÙƒ (Ø¨ØµÙŠØºØ© ÙƒÙˆØ¯)
        if platform == "tiktok" and "video_segments" in brain:
            formatted_prompts = "ğŸš€ **SUPREME ADVISOR VIDEO BLUEPRINT (9:16)**\n\n"
            for seg in brain["video_segments"]:
                formatted_prompts += f"### Scene: {seg['time']}\n```text\n{seg['prompt']}\n```\n\n"
            payload["video_prompt"] = formatted_prompts
        else:
            payload["video_prompt"] = brain.get("visual_prompt", "")

        return jsonify(payload), 200

    except Exception as e:
        logger.error(f"DEPLOYMENT CRASH: {str(e)}")
        return jsonify({"error": f"Internal Crash: {str(e)}"}), 500

if __name__ == "__main__":
    port = int(os.getenv("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
