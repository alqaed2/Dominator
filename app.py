import os
import re
import requests
import json
import urllib.parse
import random
import logging
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©
from dominator_brain import strategic_intelligence_core, alchemy_fusion_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)
logging.basicConfig(level=logging.INFO)

# ========= Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª AI Ùˆ Apify =========
GENAI_KEY = os.getenv("GEMINI_API_KEY")
APIFY_KEY = os.getenv("APIFY_API_KEY")

if GENAI_KEY:
    genai.configure(api_key=GENAI_KEY)

MODELS_POOL = ["gemini-1.5-flash", "gemini-2.0-flash-lite-001", "gemini-flash-latest"]

def get_ai_response_nebula(prompt: str) -> str:
    """Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø®Ø±ÙˆØ¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
    for model_name in MODELS_POOL:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except: continue
    return "ğŸš¨ ÙƒØ§ÙØ© Ø®Ø·ÙˆØ· Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø´ØºÙˆÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."

def fetch_live_dna(niche, target_data=None):
    """Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬ Ø§Ù„Ù…Ø·ÙˆØ±"""
    search_url = f"https://x.com/search?q={urllib.parse.quote(niche)}&f=live"
    if target_data and len(target_data.strip()) > 10:
        return [{"text": target_data, "engagement": "Confirmed", "author": "Target", "url": target_data, "is_live": True, "score": 100}]
    
    if APIFY_KEY:
        try:
            url = f"https://api.apify.com/v2/acts/apidojo~tweet-scraper/run-sync-get-dataset-items?token={APIFY_KEY}"
            res = requests.post(url, json={"searchTerms": [niche], "maxTweets": 3, "searchMode": "latest"}, timeout=25)
            if res.status_code in [200, 201]:
                data = res.json()
                return [{"text": i.get("full_text") or i.get("text"), "engagement": i.get("favorite_count", 0), "author": i.get("user", {}).get("screen_name", "user"), "url": f"https://x.com/i/status/{i.get('id_str')}", "is_live": True, "score": 90} for i in data if i.get("text")]
        except: pass
    return [{"text": f"ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ù„Ù€ {niche}", "engagement": "100K", "author": "Dominator_AI", "url": search_url, "is_live": False, "score": 95}]

def robust_parse(text):
    """Ù…ÙÙƒÙƒ Ù†ØµÙˆØµ Ø­ØµÙŠÙ† ÙŠÙ…Ù†Ø¹ Ø®Ø·Ø£ 500 Ø­ØªÙ‰ Ù„Ùˆ ÙØ´Ù„ Ø§Ù„Ù€ AI ÙÙŠ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚"""
    parts = {"linkedin": "", "twitter": "", "tiktok": "", "visual": "Luxurious professional modern office, cinematic lighting"}
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù‚ØªÙ†Ø§Øµ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Regex Ù…Ø±Ù†
    ln = re.search(r"\[LINKEDIN\](.*?)(?=\[TWITTER\]|\[TIKTOK\]|\[VISUAL_PROMPT\]|$)", text, re.S | re.I)
    tw = re.search(r"\[TWITTER\](.*?)(?=\[LINKEDIN\]|\[TIKTOK\]|\[VISUAL_PROMPT\]|$)", text, re.S | re.I)
    tk = re.search(r"\[TIKTOK\](.*?)(?=\[LINKEDIN\]|\[TWITTER\]|\[VISUAL_PROMPT\]|$)", text, re.S | re.I)
    vs = re.search(r"\[VISUAL_PROMPT\](.*?)$", text, re.S | re.I)
    
    if ln: parts["linkedin"] = ln.group(1).strip()
    if tw: parts["twitter"] = tw.group(1).strip()
    if tk: parts["tiktok"] = tk.group(1).strip()
    if vs: parts["visual"] = vs.group(1).strip()
    
    # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„ØªÙ‚Ø³ÙŠÙ…ØŒ Ù†Ø¶Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙŠ LinkedIn ÙƒØ®ÙŠØ§Ø± Ø¨Ø¯ÙŠÙ„
    if not parts["linkedin"]: parts["linkedin"] = text
    return parts

@app.route("/")
def home(): return render_template("index.html")

@app.route("/alchemy/discover", methods=["POST"])
def discover():
    try:
        data = request.get_json(silent=True) or {}
        posts = fetch_live_dna(data.get("niche", "Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©"), data.get("target_data", ""))
        fusion = alchemy_fusion_core(posts, data.get("niche", "Ø§Ù„Ø³ÙŠØ§Ø¯Ø©"))
        output = get_ai_response_nebula(f"{WPIL_DOMINATOR_SYSTEM}\n{fusion['synthesis_task']}")
        return jsonify({"super_post": output, "sources": posts}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/generate_all", methods=["POST"])
def generate():
    try:
        data = request.get_json(silent=True) or {}
        idea = data.get("text", "Ø§Ù„Ø³ÙŠØ§Ø¯Ø©")
        prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØªÙˆÙ„ÙŠØ¯ Ø­Ø²Ù…Ø© Ø³ÙŠØ§Ø¯ÙŠØ© ÙƒØ§Ù…Ù„Ø© (LinkedIn, X, TikTok) ÙˆØµÙˆØ±Ø© ÙˆØ§Ù‚Ø¹ÙŠØ© Ù„Ù„ÙÙƒØ±Ø©: {idea}"
        raw = get_ai_response_nebula(prompt)
        parsed = robust_parse(raw)
        
        # Ù…Ø­Ø±Ùƒ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠ
        seed = random.randint(1, 99999)
        quoted_prompt = urllib.parse.quote(parsed['visual'])
        image_url = f"https://image.pollinations.ai/prompt/{quoted_prompt}?width=1080&height=1350&model=flux&seed={seed}&nologo=true"
        
        brain = strategic_intelligence_core(idea)
        return jsonify({**parsed, "image_url": image_url, "video_prompt": brain["video_segments"]}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
