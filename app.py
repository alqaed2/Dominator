import os
import sys
import json
import logging
import requests  # Ù†Ø­ØªØ§Ø¬ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù„Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Apify
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai
from dominator_brain import strategic_intelligence_core, alchemy_fusion_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Ø¥Ø¹Ø¯Ø§Ø¯ AI
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
MODELS_PRIORITY = ["gemini-2.0-flash-lite", "gemini-flash-latest"]

# ========= Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Apify Ù„Ù„Ø±Ø¨Ø· Ø§Ù„Ø­ÙŠ =========
APIFY_API_KEY = os.getenv("APIFY_API_KEY")

def fetch_real_gold_posts(niche):
    """
    Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ø­ÙŠ: ÙŠØªØµÙ„ Ø¨Ù€ Apify Ù„Ø³Ø­Ø¨ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù†Ø´ÙˆØ±Ø§Øª.
    """
    if not APIFY_API_KEY:
        logger.warning("APIFY_API_KEY missing. Falling back to internal DNA storage.")
        return get_mock_gold_posts(niche)

    try:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Actor Ù…ØªØ®ØµØµ ÙÙŠ Ø³Ø­Ø¨ ØªØ±Ù†Ø¯Ø§Øª X (ÙƒÙ…Ø«Ø§Ù„ Ù‚ÙˆÙŠ Ù„Ù„Ø§Ù†ØªØ´Ø§Ø±)
        # Ù‡Ø°Ø§ Ø§Ù„Ù€ Actor ÙŠØ¨Ø­Ø« Ø¹Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ù†ÙŠØ´ ÙˆÙŠØ¬Ù„Ø¨ Ø§Ù„Ø£Ø¹Ù„Ù‰ ØªÙØ§Ø¹Ù„Ø§Ù‹
        actor_url = "https://api.apify.com/v2/acts/apidojo~tweet-scraper/run-sync-get-dataset-items"
        payload = {
            "searchMode": "top",
            "searchTerms": [niche],
            "maxTweets": 5,
            "addUserInfo": True
        }
        
        response = requests.post(
            f"{actor_url}?token={APIFY_API_KEY}", 
            json=payload, 
            timeout=45 # Ù…Ù‡Ù„Ø© ÙƒØ§ÙÙŠØ© Ù„Ù„Ø³Ø­Ø¨
        )
        
        if response.status_code == 201 or response.status_code == 200:
            raw_data = response.json()
            gold_posts = []
            for item in raw_data:
                gold_posts.append({
                    "text": item.get("full_text") or item.get("text", ""),
                    "engagement": f"{item.get('retweet_count', 0) + item.get('favorite_count', 0)} Interactions",
                    "platform": "X (Twitter)"
                })
            return gold_posts if gold_posts else get_mock_gold_posts(niche)
        
        return get_mock_gold_posts(niche)
    except Exception as e:
        logger.error(f"Apify Connection Error: {e}")
        return get_mock_gold_posts(niche)

def get_mock_gold_posts(niche):
    """Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„ ØªØ¹Ø·Ù„ Ø§Ù„Ø±Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ"""
    return [
        {"text": f"Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø®ÙÙŠØ© Ù„Ù„Ø³ÙŠØ·Ø±Ø© Ø¹Ù„Ù‰ {niche} ÙÙŠ 2026...", "engagement": "Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©", "platform": "Deep Logic"},
        {"text": f"Ù„Ù…Ø§Ø°Ø§ ÙŠÙ†Ù‡Ø§Ø± Ø§Ù„Ù…Ù†Ø§ÙØ³ÙˆÙ† ÙÙŠ Ù…Ø¬Ø§Ù„ {niche}ØŸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„.", "engagement": "Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©", "platform": "Deep Logic"}
    ]

def get_ai_response(prompt: str) -> str:
    for model_name in MODELS_PRIORITY:
        try:
            model = genai.GenerativeModel(model_name)
            return model.generate_content(prompt).text
        except: continue
    return "Error: AI Engines Busy."

@app.route("/")
def home(): return render_template("index.html")

@app.route("/alchemy/discover", methods=["POST"])
def discover_gold():
    data = request.get_json(silent=True) or {}
    niche = data.get("niche", "Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©")
    
    # 1. Ø§Ù„Ø³Ø­Ø¨ Ø§Ù„Ø­ÙŠ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø¹Ø¨Ø± Apify
    gold_posts = fetch_real_gold_posts(niche)
    
    # 2. ØªØ´ØºÙŠÙ„ Ù…ÙØ§Ø¹Ù„ Ø§Ù„Ø§Ù†Ø¯Ù…Ø§Ø¬ (Synthesis)
    fusion_data = alchemy_fusion_core(gold_posts, niche)
    
    # 3. ØªØ®Ù„ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø´ÙˆØ± Ø§Ù„Ø®Ø§Ø±Ù‚ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒÙŠ
    super_post_text = get_ai_response(f"{WPIL_DOMINATOR_SYSTEM}\n{fusion_data['synthesis_task']}")
    
    return jsonify({
        "super_post": super_post_text,
        "score": fusion_data["dominance_score"],
        "sources": gold_posts,
        "trace": fusion_data["logic_trace"]
    }), 200

@app.route("/generate/<platform>", methods=["POST", "GET"])
def handle_execution(platform="linkedin"):
    # (Ù†ÙØ³ Ù…Ù†Ø·Ù‚ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©)
    data = request.get_json(force=True, silent=True) or {}
    idea = data.get('text') or data.get('idea') or ""
    seed = data.get('winning_post') or ""
    brain = strategic_intelligence_core(idea, platform, "default", seed)
    prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØ§Ù„Ù…Ù‡Ù…Ø©: {brain['transformed_input']}\nØ§Ù„Ù…Ù†ØµØ©: {platform}"
    text_raw = get_ai_response(prompt)
    
    payload = {
        "platform": platform, 
        "text": f"{text_raw}{brain.get('viral_signature','')}",
        "trace": brain["logic_trace"]
    }
    if platform == "tiktok":
        v_prompt = "ğŸš€ **VERTICAL 9:16 PROMPTS**\n\n"
        for seg in brain["video_segments"]:
            v_prompt += f"### {seg['time']}\n```text\n{seg['prompt']}\n```\n\n"
        payload["video_prompt"] = v_prompt
    return jsonify(payload), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
