import os
import sys
import json
import logging
import time
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai
from dominator_brain import strategic_intelligence_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
logger = logging.getLogger(__name__)

# ========= Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ø±ÙƒØ§Øª AI (Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© 2025) =========
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Ù…ØµÙÙˆÙØ© Ø§Ù„Ù‡ÙŠÙ…Ù†Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø©: ØªØ¹Ø·ÙŠ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø°Ø§Øª Ø§Ù„Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø¹Ø§Ù„ÙŠØ© (High Quota)
MODELS_PRIORITY = [
    "gemini-2.0-flash-lite",   # Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£Ø¹Ù„Ù‰ ÙÙŠ Ø­Ø¯ÙˆØ¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª (Quota)
    "gemini-flash-latest",     # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙ‚Ø± (1.5 Flash) - Ø­Ø¯ÙˆØ¯ Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹
    "gemini-2.0-flash",       # ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø°ÙƒØ§Ø¡ ÙˆØ§Ù„Ø³Ø±Ø¹Ø©
    "gemini-2.5-flash-lite",  # Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚Ù…Ø© Ø¨Ù†Ø³Ø®Ø© Lite
    "gemini-2.5-flash"        # Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£Ø®ÙŠØ± (Ù‚ÙŠÙˆØ¯ ØµØ§Ø±Ù…Ø©)
]

def get_ai_response_with_failover(prompt: str) -> str:
    last_error = ""
    for model_name in MODELS_PRIORITY:
        try:
            logger.info(f"ğŸš€ Deploying on: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            last_error = str(e)
            logger.warning(f"âš ï¸ {model_name} busy or limited. Error: {last_error[:50]}...")
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ 429 (Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ²)ØŒ Ù†Ù†ØªÙ‚Ù„ ÙÙˆØ±Ø§Ù‹ Ù„Ù„ØªØ§Ù„ÙŠ
            if "429" in last_error or "Quota" in last_error:
                continue
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø®Ø·Ø£ 404 (Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯)ØŒ Ù†Ù†ØªÙ‚Ù„ Ù„Ù„ØªØ§Ù„ÙŠ
            if "404" in last_error:
                continue
            return f"Strategic Engine Error: {last_error}"
    
    return f"âš ï¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ù…Ø´ØºÙˆÙ„Ø© Ø¨Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± 30 Ø«Ø§Ù†ÙŠØ© ÙˆØ§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ù„ÙØªØ­ Ù…Ø³Ø§Ø± Ø¬Ø¯ÙŠØ¯."

# ========= Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø°ÙƒÙŠØ§Ù‹ =========
def extract_ui_data():
    data = {}
    try:
        data = request.get_json(force=True, silent=True) or {}
    except: data = {}
    if request.form: data.update(request.form.to_dict())

    idea = data.get('text') or data.get('idea') or data.get('topic') or ""
    seed = data.get('winning_post') or data.get('seed') or ""
    style = data.get('style_dna') or data.get('style') or "Professional"
    
    return str(idea).strip(), str(seed).strip(), str(style).strip()

# ========= Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© =========

@app.route("/", methods=["GET"])
def home():
    return render_template("index.html")

@app.route("/generate/<platform>", methods=["POST", "GET"])
@app.route("/remix", methods=["POST", "GET"])
def handle_execution(platform="linkedin"):
    if request.method == "GET":
        return jsonify({"status": "ready"}), 200

    if request.path == "/remix": platform = "linkedin"

    idea, seed, style = extract_ui_data()
    actual_content = idea if idea else seed
    
    if not actual_content:
        return jsonify({"error": "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„"}), 400

    try:
        # 1. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯Ù…Ø§Øº
        brain = strategic_intelligence_core(idea, platform, style, seed)
        
        # 2. ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ù€ Failover Ø§Ù„Ø°ÙƒÙŠ
        final_prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØ§Ù„Ù…Ù†ØµØ©: {platform}\nØ§Ù„Ù…Ù‡Ù…Ø©: {brain['transformed_input']}\nØ§Ù„Ø£Ø³Ù„ÙˆØ¨: {style}"
        generated_text = get_ai_response_with_failover(final_prompt)

        payload = {
            "platform": platform,
            "text": generated_text,
            "trace": brain["logic_trace"],
            "remixed_seed": idea if idea else seed,
            "sic_transformed_input": brain['transformed_input']
        }

        # 3. Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„ØªÙŠÙƒ ØªÙˆÙƒ
        if platform == "tiktok" and "video_segments" in brain:
            formatted_prompts = "ğŸ¥ **SUPREME ADVISOR VIDEO BLUEPRINT (9:16)**\n\n"
            for seg in brain["video_segments"]:
                formatted_prompts += f"### Scene: {seg['time']}\n```text\n{seg['prompt']}\n```\n\n"
            payload["video_prompt"] = formatted_prompts
        else:
            payload["video_prompt"] = brain.get("visual_prompt", "")

        return jsonify(payload), 200

    except Exception as e:
        logger.error(f"CRITICAL CRASH: {str(e)}")
        return jsonify({"error": f"Internal Error: {str(e)}"}), 500

if __name__ == "__main__":
    port = int(os.getenv("PORT", 5000))
    app.run(host="0.0.0.0", port=port)
