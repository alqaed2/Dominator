import os
import re
import requests
import urllib.parse
import random
import time
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©
from dominator_brain import strategic_intelligence_core, alchemy_fusion_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)

# ========= ØªØ±Ø³Ø§Ù†Ø© Nebula v14.1 Ø§Ù„Ù…ÙˆØ³Ø¹Ø© (7 Ù…ÙˆØ¯ÙŠÙ„Ø§Øª) =========
MODELS_POOL = [
    "gemini-2.0-flash-lite-001", # Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£ÙƒØ«Ø± ØªÙˆÙØ±Ø§Ù‹
    "gemini-2.5-flash-lite",     # Ø­ØµØ§Ù†Ø© Ø¹Ø§Ù„ÙŠØ© Ø¶Ø¯ Ø§Ù„Ø¶ØºØ·
    "gemini-2.0-flash",          # ØªÙˆØ§Ø²Ù† Ø°ÙƒØ§Ø¡
    "gemini-2.5-flash",          # Ø§Ù„Ù‚Ù…Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
    "gemini-flash-latest",       # Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø³ØªÙ‚Ø± 1.5
    "gemini-pro-latest",         # Ø§Ù„Ù…Ù„Ø§Ø° Ø§Ù„Ø£Ø®ÙŠØ±
    "gemini-1.5-flash"           # Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
]

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
APIFY_KEY = os.getenv("APIFY_API_KEY")

def get_ai_response_nebula_v14(prompt: str) -> str:
    """Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Nebula Ø§Ù„Ù…Ø·ÙˆØ±: Ø¬ÙˆÙ„Ø© Ù‚Ø³Ø±ÙŠØ© Ø¹Ø¨Ø± 7 Ù…Ø­Ø±ÙƒØ§Øª Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©"""
    for model_name in MODELS_POOL:
        try:
            print(f"ğŸ“¡ [COMMAND] Deploying Intelligence on: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            if response and response.text:
                return response.text
        except Exception as e:
            print(f"âš ï¸ [RETRY] {model_name} bypassed. Logic: {str(e)[:40]}")
            time.sleep(0.5) # Ø§Ù†ØªØ¸Ø§Ø± ØªÙ‚Ù†ÙŠ Ø¨Ø³ÙŠØ· Ù„Ù…Ù†Ø¹ Ø§Ù„Ø­Ø¸Ø± Ø§Ù„Ù„Ø­Ø¸ÙŠ
            continue
    return "ğŸš¨ ÙƒØ§ÙØ© Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ù…Ø´ØºÙˆÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ 10 Ø«ÙˆØ§Ù†Ù."

def parse_v14(text):
    parts = {"linkedin": "", "twitter": "", "tiktok": "", "visual": "High-end professional business photography, realistic"}
    patterns = {
        "linkedin": r"\[LINKEDIN\](.*?)(?=\[TWITTER\]|\[TIKTOK\]|\[VISUAL_PROMPT\]|$)",
        "twitter": r"\[TWITTER\](.*?)(?=\[LINKEDIN\]|\[TIKTOK\]|\[VISUAL_PROMPT\]|$)",
        "tiktok": r"\[TIKTOK\](.*?)(?=\[LINKEDIN\]|\[TWITTER\]|\[VISUAL_PROMPT\]|$)",
        "visual": r"\[VISUAL_PROMPT\](.*?)$"
    }
    for key, pat in patterns.items():
        match = re.search(pat, text, re.S | re.I)
        if match: parts[key] = match.group(1).strip()
    if not parts["linkedin"]: parts["linkedin"] = text
    return parts

@app.route("/")
def home(): return render_template("index.html")

@app.route("/alchemy/discover", methods=["POST"])
def discover():
    try:
        data = request.get_json(silent=True) or {}
        target = data.get("target_data", "")
        niche = data.get("niche", "Ø§Ù„Ø³ÙŠØ§Ø¯Ø©")
        posts = [{"text": target if target else f"Trend in {niche}", "engagement": "Confirmed", "author": "Target"}]
        fusion = alchemy_fusion_core(posts, niche)
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Nebula Ù„ØªØ®Ù„ÙŠÙ‚ Ø§Ù„Ù…Ø®ØªØ¨Ø±
        output = get_ai_response_nebula_v14(f"{WPIL_DOMINATOR_SYSTEM}\n{fusion['synthesis_task']}")
        return jsonify({"super_post": output, "sources": posts}), 200
    except Exception as e: return jsonify({"error": str(e)}), 500

@app.route("/generate_all", methods=["POST"])
def generate():
    try:
        data = request.get_json(silent=True) or {}
        idea = data.get("text", "Ø§Ù„Ø³ÙŠØ§Ø¯Ø©")
        prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØªÙˆÙ„ÙŠØ¯ Ø­Ø²Ù…Ø© Ø³ÙŠØ§Ø¯ÙŠØ© ÙƒØ§Ù…Ù„Ø© Ù…ØªÙˆØ§ÙÙ‚Ø© Ø­Ø±ÙÙŠØ§Ù‹ Ù…Ø¹ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {idea}\nØ£Ù†Ù‡Ù Ø¨Ù€ [VISUAL_PROMPT]."
        raw = get_ai_response_nebula_v14(prompt)
        parsed = parse_v14(raw)
        
        seed = random.randint(1, 99999)
        quoted_v = urllib.parse.quote(parsed['visual'])
        image_url = f"https://image.pollinations.ai/prompt/{quoted_v}?seed={seed}&width=1024&height=1024&model=flux&nologo=true"
        
        brain = strategic_intelligence_core(idea)
        return jsonify({**parsed, "image_url": image_url, "video_blueprint": brain["video_segments"]}), 200
    except Exception as e: return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
