import os
import requests
import time
import logging
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©
from dominator_brain import strategic_intelligence_core, alchemy_fusion_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)
logger = logging.getLogger(__name__)

# ========= ØªØ±Ø³Ø§Ù†Ø© Ù…ÙˆØ¯ÙŠÙ„Ø§Øª 2025 Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ù…Ù† Ù‚Ø§Ø¦Ù…ØªÙƒ Ø§Ù„Ù…ØªØ§Ø­Ø© =========
MODELS_POOL = [
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.0-flash-lite-001",
    "gemini-flash-latest",
    "gemini-pro-latest"
]

GENAI_KEY = os.getenv("GEMINI_API_KEY")
APIFY_KEY = os.getenv("APIFY_API_KEY")

if GENAI_KEY:
    genai.configure(api_key=GENAI_KEY)

def get_ai_response_nebula(prompt: str) -> str:
    """
    Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„ Nebula: Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù‚Ø³Ø±ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ÙÙŠ Ø­Ø§Ù„ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø­ØµØ© (Quota)
    """
    last_error = ""
    for model_name in MODELS_POOL:
        try:
            print(f"ğŸ“¡ [COMMAND] Deploying model: {model_name}")
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(prompt)
            return response.text
        except Exception as e:
            last_error = str(e)
            print(f"âš ï¸ [WARNING] Model {model_name} failed. Error: {last_error[:50]}...")
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ù…ØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ø­ØµØ© (429) Ø£Ùˆ Ø¹Ø¯Ù… Ø§Ù„ØªÙˆÙØ± (404/500)ØŒ Ù†Ù†ØªÙ‚Ù„ ÙÙˆØ±Ø§Ù‹
            continue
            
    return f"ğŸš¨ ÙƒØ§ÙØ© Ø®Ø·ÙˆØ· Ø§Ù„Ø§ØªØµØ§Ù„ Ø§Ù„Ø¹ØµØ¨ÙŠØ© Ù…Ø´ØºÙˆÙ„Ø©. Ø¢Ø®Ø± Ø¥Ø´Ø¹Ø§Ø±: {last_error}"

def fetch_real_gold_posts(niche):
    if APIFY_KEY:
        try:
            url = f"https://api.apify.com/v2/acts/apidojo~tweet-scraper/run-sync-get-dataset-items?token={APIFY_KEY}"
            res = requests.post(url, json={"searchTerms": [niche], "maxTweets": 5, "searchMode": "top"}, timeout=15)
            if res.status_code in [200, 201]:
                return [{"text": i.get("full_text") or i.get("text", "DNA"), "engagement": f"{i.get('favorite_count', 0)} Likes"} for i in res.json()]
        except: pass
    
    return [
        {"text": f"Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ© Ù„Ù„Ù‡ÙŠÙ…Ù†Ø© ÙÙŠ {niche} Ù„Ø¹Ø§Ù… 2026", "engagement": "150K+"},
        {"text": f"Ù„Ù…Ø§Ø°Ø§ ÙŠÙƒØªØ³Ø­ Ø§Ù„Ù‚Ø§Ø¯Ø© Ø³ÙˆÙ‚ {niche}ØŸ Ø¥Ù„ÙŠÙƒ Ø§Ù„Ø³Ø± Ø§Ù„Ø®ÙÙŠ", "engagement": "90K+"}
    ]

@app.route("/")
def home(): return render_template("index.html")

@app.route("/alchemy/discover", methods=["POST"])
def discover():
    data = request.get_json(silent=True) or {}
    niche = data.get("niche", "Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©")
    posts = fetch_real_gold_posts(niche)
    fusion = alchemy_fusion_core(posts, niche)
    # ØªØ´ØºÙŠÙ„ Nebula Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ®Ù„ÙŠÙ‚
    output = get_ai_response_nebula(f"{WPIL_DOMINATOR_SYSTEM}\n{fusion['synthesis_task']}")
    return jsonify({"super_post": output, "sources": posts, "trace": fusion["logic_trace"]}), 200

@app.route("/generate_all", methods=["POST"])
def generate_all():
    data = request.get_json(silent=True) or {}
    idea = data.get('text') or "Ø§Ù„Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©"
    prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØ§Ù„Ù…Ù‡Ù…Ø©: ØªÙˆÙ„ÙŠØ¯ 3 Ù†Ø³Ø® (LinkedIn, X, TikTok) Ù„Ù‡Ø°Ù‡ Ø§Ù„ÙÙƒØ±Ø©: {idea}\nØ§Ù„Ù†Ø§ØªØ¬ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ù†Ø³Ù‚Ø§Ù‹ Ø¨ÙØ®Ø§Ù…Ø©."
    # ØªØ´ØºÙŠÙ„ Nebula Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¹Ø§Ø¨Ø± Ù„Ù„Ù…Ù†ØµØ§Øª
    output = get_ai_response_nebula(prompt)
    brain = strategic_intelligence_core(idea)
    return jsonify({"combined_text": output, "trace": brain["logic_trace"], "video_prompt": brain["video_segments"]}), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
