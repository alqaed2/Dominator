import os
import re
import requests
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import google.generativeai as genai

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†ÙˆØ§Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©
from dominator_brain import strategic_intelligence_core, alchemy_fusion_core, WPIL_DOMINATOR_SYSTEM

app = Flask(__name__, template_folder="templates", static_folder="static")
CORS(app)

# ========= ØªØ±Ø³Ø§Ù†Ø© Nebula Ù„Ø¹Ø§Ù… 2025 =========
MODELS_POOL = [
    "gemini-2.5-flash",
    "gemini-2.5-flash-lite",
    "gemini-2.0-flash-lite-001",
    "gemini-flash-latest",
    "gemini-pro-latest"
]

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
APIFY_KEY = os.getenv("APIFY_API_KEY")

def get_ai_response_nebula(prompt: str) -> str:
    for model_name in MODELS_POOL:
        try:
            model = genai.GenerativeModel(model_name)
            return model.generate_content(prompt).text
        except: continue
    return "ğŸš¨ ÙƒØ§ÙØ© Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ù…Ø´ØºÙˆÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹."

def fetch_live_dna(niche):
    # Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø£Ø¨Ø¯Ø§Ù‹
    fallback_url = f"https://twitter.com/search?q={niche}&f=live"
    
    if APIFY_KEY:
        try:
            url = f"https://api.apify.com/v2/acts/apidojo~tweet-scraper/run-sync-get-dataset-items?token={APIFY_KEY}"
            res = requests.post(url, json={"searchTerms": [niche], "maxTweets": 5, "searchMode": "top"}, timeout=20)
            if res.status_code in [200, 201]:
                data = res.json()
                if data:
                    return [{
                        "text": i.get("text", "DNA Sample"), 
                        "engagement": f"{i.get('favorite_count', 0)}",
                        "author": i.get("user", {}).get("screen_name", "Elite_Insight"),
                        "url": i.get("url") or f"https://twitter.com/i/web/status/{i.get('id_str')}",
                        "score": 85 + (i.get('favorite_count', 0) % 15)
                    } for i in data if i.get("text")]
        except: pass
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¯ÙŠÙ„Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ù…Ø¹ Ø±ÙˆØ§Ø¨Ø· Ø¨Ø­Ø« Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙŠ Ø§Ù„Ù†ÙŠØ´
    return [
        {"text": f"ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ù„Ø§ÙƒØªØ³Ø§Ø­ {niche} ÙÙŠ 2026", "engagement": "120K", "author": "Dominator_AI", "url": fallback_url, "score": 95},
        {"text": f"Ù„Ù…Ø§Ø°Ø§ ÙŠØ³ÙŠØ·Ø± Ø§Ù„Ù‚Ø§Ø¯Ø© Ø¹Ù„Ù‰ Ø³ÙˆÙ‚ {niche}ØŸ", "engagement": "85K", "author": "Market_Oracle", "url": fallback_url, "score": 90}
    ]

def parse_output(text):
    parts = {"linkedin": "", "twitter": "", "tiktok": ""}
    for p in parts:
        match = re.search(rf"\[{p.upper()}\](.*?)(\[|$)", text, re.S | re.I)
        parts[p] = match.group(1).strip() if match else "ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‚Ø³Ù…"
    return parts

@app.route("/")
def home(): return render_template("index.html")

@app.route("/alchemy/discover", methods=["POST"])
def discover():
    data = request.get_json(silent=True) or {}
    niche = data.get("niche", "Ø±ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ø¹Ù…Ø§Ù„")
    posts = fetch_live_dna(niche)
    fusion = alchemy_fusion_core(posts, niche)
    output = get_ai_response_nebula(f"{WPIL_DOMINATOR_SYSTEM}\n{fusion['synthesis_task']}")
    return jsonify({"super_post": output, "sources": posts}), 200

@app.route("/generate_all", methods=["POST"])
def generate():
    idea = request.get_json().get("text", "Ø§Ù„Ø³ÙŠØ§Ø¯Ø©")
    prompt = f"{WPIL_DOMINATOR_SYSTEM}\nØªÙˆÙ„ÙŠØ¯ Ù…Ø­ØªÙˆÙ‰ Ù„Ù€ [LINKEDIN], [TWITTER], [TIKTOK] Ù„Ù‡Ø°Ù‡ Ø§Ù„ÙÙƒØ±Ø©: {idea}"
    raw = get_ai_response_nebula(prompt)
    parsed = parse_output(raw)
    brain = strategic_intelligence_core(idea)
    return jsonify({**parsed, "video_prompt": brain["video_segments"]}), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", 5000)))
